{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"C:\\TradeGroup\")\n",
    "my_wd = os.getcwd()\n",
    "new_directory = my_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Exists\n"
     ]
    }
   ],
   "source": [
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(f'{new_directory}/{folder_path}'):\n",
    "        os.makedirs(f'{new_directory}/{folder_path}')\n",
    "    else:\n",
    "        print(f'Already Exists')\n",
    "\n",
    "create_folder('Data/HS_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_HS2(tcode):\n",
    "    tcode=str(tcode)\n",
    "    if len(tcode)==7 or len(tcode)==5 or len(tcode)==9:\n",
    "        return tcode[0]\n",
    "    elif len(tcode)==8 or len(tcode)==6 or len(tcode)==10:\n",
    "        return tcode[:2]\n",
    "    \n",
    "def generate_HS4(tcode):\n",
    "    tcode=str(tcode)\n",
    "    if len(tcode)==7 or len(tcode)==5 or len(tcode)==9:\n",
    "        return tcode[:3]\n",
    "    elif len(tcode)==8 or len(tcode)==6 or len(tcode)==10:\n",
    "        return tcode[:4]  \n",
    "\n",
    "\n",
    "def generate_HS6(tcode):\n",
    "    tcode=str(tcode)\n",
    "    if len(tcode)==7 or len(tcode)==5 or len(tcode)==9:\n",
    "        return tcode[:5]\n",
    "    elif len(tcode)==8 or len(tcode)==6 or len(tcode)==10:\n",
    "        return tcode[:6]          \n",
    "\n",
    "\n",
    "def generate_HS8(tcode):\n",
    "    tcode=str(tcode)\n",
    "    if len(tcode)==7 or len(tcode)==5 or len(tcode)==9:\n",
    "        return tcode[:7]\n",
    "    elif len(tcode)==8 or len(tcode)==6 or len(tcode)==10:\n",
    "        return tcode[:8]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375\n",
      "Was Completed\n",
      "1376\n",
      "Was Completed\n",
      "1377\n",
      "Was Completed\n",
      "1378\n",
      "Was Completed\n",
      "1379\n",
      "Was Completed\n",
      "1380\n",
      "Was Completed\n",
      "1381\n",
      "Was Completed\n",
      "1382\n",
      "Was Completed\n"
     ]
    }
   ],
   "source": [
    "for year in range(1375,1383):\n",
    "    exports_file_path = f\"{my_wd}/Data/Cleaned_Data/Y{year}Exports.xlsx\"\n",
    "    imports_file_path = f\"{my_wd}/Data/Cleaned_Data/Y{year}Imports.xlsx\"\n",
    "    #if year!=1394:\n",
    "    Exports = pd.read_excel(exports_file_path)\n",
    "    Imports = pd.read_excel(imports_file_path)\n",
    "\n",
    "    Imports.dropna(subset='Tcode',inplace=True)\n",
    "    Exports.dropna(subset=\"Tcode\",inplace=True)\n",
    "\n",
    "    Imports['HS2']=Imports['Tcode'].astype('int64').apply(generate_HS2)\n",
    "    Exports['HS2']=Exports['Tcode'].astype('int64').apply(generate_HS2)\n",
    "\n",
    "    Imports['HS4']=Imports['Tcode'].astype('int64').apply(generate_HS4)\n",
    "    Exports['HS4']=Exports['Tcode'].astype('int64').apply(generate_HS4)    \n",
    "\n",
    "\n",
    "\n",
    "    HS2_Imports = Imports.groupby('HS2').agg(\n",
    "    Weight_Imp=('Weight', 'sum'),\n",
    "    Rials_Imp=('Rials', 'sum'),\n",
    "    Dollars_Imp=('Dollars', 'sum')\n",
    "    ).reset_index().assign(Year=year)\n",
    "\n",
    "\n",
    "\n",
    "    HS2_Exports = Exports.groupby('HS2').agg(\n",
    "    Weight_Exp=('Weight', 'sum'),\n",
    "    Rials_Exp=('Rials', 'sum'),\n",
    "    Dollars_Exp=('Dollars', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HS4_Imports = Imports.groupby('HS4').agg(\n",
    "    Weight_Imp=('Weight', 'sum'),\n",
    "    Rials_Imp=('Rials', 'sum'),\n",
    "    Dollars_Imp=('Dollars', 'sum')\n",
    "    ).reset_index().assign(Year=year)\n",
    "\n",
    "    HS4_Exports = Exports.groupby('HS4').agg(\n",
    "    Weight_Exp=('Weight', 'sum'),\n",
    "    Rials_Exp=('Rials', 'sum'),\n",
    "    Dollars_Exp=('Dollars', 'sum')\n",
    "    ).reset_index()   \n",
    "\n",
    "    HS2_Trade = pd.merge(HS2_Exports, HS2_Imports, on='HS2', how='outer')\n",
    "    HS4_Trade = pd.merge(HS4_Exports, HS4_Imports, on='HS4', how='outer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HS2_Trade.to_excel(f\"{my_wd}/Data/HS_Data/Y{year}HS2Trade.xlsx\", index=False)\n",
    "    HS4_Trade.to_excel(f\"{my_wd}/Data/HS_Data/Y{year}HS4Trade.xlsx\", index=False) \n",
    "\n",
    "    print(year)  \n",
    "    print(\"Was Completed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1390\n",
      "Was Completed\n",
      "1391\n",
      "Was Completed\n",
      "1392\n",
      "Was Completed\n",
      "1393\n",
      "Was Completed\n",
      "1394\n",
      "Was Completed\n"
     ]
    }
   ],
   "source": [
    "original_code=\"\"\"\n",
    "for year in range(1390,1395):\n",
    "    exports_file_path = f\"{my_wd}/Data/Cleaned_Data/Y{year}Exports.xlsx\"\n",
    "    imports_file_path = f\"{my_wd}/Data/Cleaned_Data/Y{year}Imports.xlsx\"\n",
    " \n",
    "    Exports = pd.read_excel(exports_file_path)\n",
    "    Imports = pd.read_excel(imports_file_path)\n",
    "\n",
    "    Imports.dropna(subset='Tcode',inplace=True)\n",
    "    Exports.dropna(subset=\"Tcode\",inplace=True)\n",
    "\n",
    "    Imports['HS2']=Imports['Tcode'].astype('int64').apply(generate_HS2)\n",
    "    Exports['HS2']=Exports['Tcode'].astype('int64').apply(generate_HS2)\n",
    "\n",
    "    Imports['HS4']=Imports['Tcode'].astype('int64').apply(generate_HS4)\n",
    "    Exports['HS4']=Exports['Tcode'].astype('int64').apply(generate_HS4)    \n",
    "\n",
    "\n",
    "\n",
    "    HS2_Imports = Imports.groupby('HS2').agg(\n",
    "    Weight_Imp=('Weight', 'sum'),\n",
    "    Rials_Imp=('Rials', 'sum'),\n",
    "    Dollars_Imp=('Dollars', 'sum')\n",
    "    ).reset_index().assign(Year=year)\n",
    "\n",
    "\n",
    "\n",
    "    HS2_Exports = Exports.groupby('HS2').agg(\n",
    "    Weight_Exp=('Weight', 'sum'),\n",
    "    Rials_Exp=('Rials', 'sum'),\n",
    "    Dollars_Exp=('Dollars', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HS4_Imports = Imports.groupby('HS4').agg(\n",
    "    Weight_Imp=('Weight', 'sum'),\n",
    "    Rials_Imp=('Rials', 'sum'),\n",
    "    Dollars_Imp=('Dollars', 'sum')\n",
    "    ).reset_index().assign(Year=year)\n",
    "\n",
    "    HS4_Exports = Exports.groupby('HS4').agg(\n",
    "    Weight_Exp=('Weight', 'sum'),\n",
    "    Rials_Exp=('Rials', 'sum'),\n",
    "    Dollars_Exp=('Dollars', 'sum')\n",
    "    ).reset_index()   \n",
    "\n",
    "    HS2_Trade = pd.merge(HS2_Exports, HS2_Imports, on='HS2', how='outer')\n",
    "    HS4_Trade = pd.merge(HS4_Exports, HS4_Imports, on='HS4', how='outer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    HS2_Trade.to_excel(f\"{my_wd}/Data/HS_Data/Y{year}HS2Trade.xlsx\", index=False)\n",
    "    HS4_Trade.to_excel(f\"{my_wd}/Data/HS_Data/Y{year}HS4Trade.xlsx\", index=False) \n",
    "\n",
    "    print(year)  \n",
    "    print(\"Was Completed\") \n",
    "\n",
    "    \"\"\"\n",
    "modified_code = original_code.replace(\"HS2\", \"HS6\").replace(\"HS4\",\"HS8\")\n",
    "\n",
    "exec(modified_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS2\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "HS4\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "HS6\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "HS8\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n"
     ]
    }
   ],
   "source": [
    "HSs=['HS2','HS4','HS6','HS8']\n",
    "hs_dataframes = {}\n",
    "hs_dataframes_series = {}\n",
    "baseyear=1390\n",
    "for hs in HSs:\n",
    "    hs_dataframes[hs] = {}\n",
    "    hs_dataframes_series[hs] = {}\n",
    "    \n",
    "    print(hs)\n",
    "    \n",
    "    for year in range(1390,1403):\n",
    "        print(year)\n",
    "        hs_file_path = f\"{my_wd}/Data/HS_Data/Y{year}{hs}Trade.xlsx\"\n",
    "        hs_file = pd.read_excel(hs_file_path)\n",
    "        hs_dataframes[hs][year] = pd.read_excel(hs_file_path)\n",
    "        if(year==baseyear):\n",
    "           cols=[hs,\"Dollars_Imp\"]\n",
    "           hs_dataframes_series[hs]=hs_dataframes[hs][year].loc[:,cols].rename(columns={\"Dollars_Imp\": f'Dollars_Imp_{year}'})\n",
    "        else:\n",
    "            hs_dataframes_series[hs]=hs_dataframes_series[hs].merge(hs_dataframes[hs][year].loc[:,cols].rename(columns={\"Dollars_Imp\": f'Imp_{year}_D'}),on=hs,how=\"outer\")  \n",
    "\n",
    "    hs_dataframes_series[hs].fillna(0,inplace=True)\n",
    "    \n",
    "\n",
    "    hs_dataframes_series[hs].to_excel(f\"{my_wd}/Data/HS_Data/{hs}_TimeSeries.xlsx\", index=False)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_plus_1  = pd.to_numeric(row[i + 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_plus_1  = pd.to_numeric(row[i + 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_plus_1  = pd.to_numeric(row[i + 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\1130648256.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_plus_1  = pd.to_numeric(row[i + 1])\n"
     ]
    }
   ],
   "source": [
    "def find_sharp_declines(row):\n",
    "    for i in range(1, len(row) - 1):  # Adjusted the range to avoid an IndexError\n",
    "        try:\n",
    "            numeric_value_i = pd.to_numeric(row[i])\n",
    "            numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
    "            numeric_value_i_plus_1  = pd.to_numeric(row[i + 1])\n",
    "            if numeric_value_i < 0.2 * numeric_value_i_minus_1 and numeric_value_i_plus_1 < 0.2 * numeric_value_i_minus_1:\n",
    "                return int(df.columns[i][-4:])\n",
    "        except (OverflowError, pd.errors.PandasError, ValueError):\n",
    "            # Handle conversion errors, e.g., if the value is not convertible to numeric\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "hs_dataframes_series = {\n",
    "    'HS2': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS2_TimeSeries.xlsx\"),\n",
    "    'HS4': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS4_TimeSeries.xlsx\"),\n",
    "    'HS6': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS6_TimeSeries.xlsx\"),\n",
    "    'HS8': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS8_TimeSeries.xlsx\"),\n",
    "}\n",
    "\n",
    "for hs in hs_dataframes_series:\n",
    "    df=hs_dataframes_series[hs]\n",
    "    df['SharpDeclineColumn'] = df.apply(find_sharp_declines, axis=1)\n",
    "\n",
    "    #Filter rows with sharp declines\n",
    "    result_df = df.dropna(subset=['SharpDeclineColumn'])\n",
    "    result_df = result_df[result_df['SharpDeclineColumn']!=1390]\n",
    "\n",
    "    result_df.to_excel(f\"{my_wd}/Data/HS_Data/{hs}_TimeSeries_SahrpDeclines_2Periods_20percent.xlsx\", index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i = pd.to_numeric(row[i])\n",
      "C:\\Users\\msbirjandi\\AppData\\Local\\Temp\\ipykernel_11440\\755130600.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n"
     ]
    }
   ],
   "source": [
    "def find_sharp_declines_all(row):\n",
    "    for i in range(1, len(row) - 1):\n",
    "        try:\n",
    "            numeric_value_i = pd.to_numeric(row[i])\n",
    "            numeric_value_i_minus_1 = pd.to_numeric(row[i - 1])\n",
    "            \n",
    "            # Check if all values in the next columns are less than 0.1 * numeric_value_i_minus_1\n",
    "            next_columns = row[i:]\n",
    "            all_below_threshold = all(pd.to_numeric(value) < 0.2 * numeric_value_i_minus_1 for value in next_columns)\n",
    "\n",
    "            if all_below_threshold:\n",
    "                return int(df.columns[i][-4:])\n",
    "        except (OverflowError, pd.errors.PandasError, ValueError):\n",
    "            # Handle conversion errors, e.g., if the value is not convertible to numeric\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "hs_dataframes_series = {\n",
    "    'HS2': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS2_TimeSeries.xlsx\"),\n",
    "    'HS4': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS4_TimeSeries.xlsx\"),\n",
    "    'HS6': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS6_TimeSeries.xlsx\"),\n",
    "    'HS8': pd.read_excel(f\"{my_wd}/Data/HS_Data/HS8_TimeSeries.xlsx\"),\n",
    "}\n",
    "\n",
    "for hs in hs_dataframes_series:\n",
    "    df=hs_dataframes_series[hs]\n",
    "    df['SharpDeclineColumn'] = df.apply(find_sharp_declines_all, axis=1)\n",
    "\n",
    "    #Filter rows with sharp declines\n",
    "    result_df = df.dropna(subset=['SharpDeclineColumn'])\n",
    "    result_df = result_df[result_df['SharpDeclineColumn']!=1390]\n",
    "\n",
    "    result_df.to_excel(f\"{my_wd}/Data/HS_Data/{hs}_TimeSeries_SahrpDeclines_All_Periods_20Percent.xlsx\", index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
